## 1. Kafka design fundamentals
生产者发布消息到topic（消息队列）——topic是发布消息的分类和别称，它被broker（做为kafka的server）创建。  
brokers也存储消息，消费者从topic（一或多）得到消息。其中brokers和消费者都使用zookeeper得到状态信息和跟踪消息的offset。

**架构（单节点-单broker-4分区）：**
>- producers1->kafkatopic（分区1）->zookeeper，kafkatopic（分区1）->消费组（消费者1）->zookeeper
>- producers2->kafkatopic（分区2、分区3）->zookeeper，kafkatopic（分区2）->消费组（消费者2）->zookeeper，kafkatopic（分区3）->消费组（消费者3）->zookeeper
>- producers3->kafkatopic（分区3）->zookeeper，kafkatopic（分区3）->消费组（消费者3）->zookeeper

>kafka的topics，每个分区都映射到逻辑日志文件（同等大小的分段文件集）
每个分区都是有序、不可改变的消息序列，一有消息发布到分区，broker就把消息追加到最后一片分段文件后面。
这些分段文件经过配置文件指定的消息数或过期时间，会刷入磁盘存储（一旦flush，消费者即可消费）。

>所有分区被连续的数字：offset标识，每个分区可选择性的容忍重复（可配置）。

>**分区可用：** 任一服务器作为leader，零或多台follower。
>>- leader负责处理所有读、写请求到分区，followers从leader异步复制数据。
kafka动态维护一份内部同步副本集，它从leader捕获并总是将最新的副本集持久化到zookeeper。若leader挂掉了，他们之间的follows（内部同步副本）将自己选举出leader。
>>- 在集群，每个服务器都扮演角色，一部分分区扮演leader、一分部扮演follower，确保集群的负载均衡。
每个消费者代表一个进程，这些进程被组织到分组内（consumer groups）
>>- 若一份消息被多客户端消费，则这些消费者的分组都不能一样。消费者总是从特定的分区顺序的获取消息的offset（意味已消费之前的所有消息）。
消费者发出异步请求（包含消息的offset）到broker消费。


>kafka的设计中，brokers是无状态的（不记录消费者是谁），任何已消费的消息，其状态在消费者中维护。如果消息从broker删除，消费者并不知道。而kafka定义了一个基于时间的SLA(服务等级协议)作为消息保留策略。
一条消息在broker中超过定义的SLA周期，即被删除。该策略允许消费者特意的倒回老的offset，重复消息数据（在传统的消息队列系统，这是违反队列通信的）。

>有多种方式传递消息： 
>> ①消息永远不被重复发送，但可能丢失；  ②消息可能重复发送，但不会丢失；    
③消息一次只发送一次。  

>- 发布时，将消息提交到日志中。若生产者在发布时网络故障，是无法确定错误发生在消息提交前或后的。
一旦提交，信息将不会丢失（只要任一broker复制到分区）
>- 对有保证的消息发布，如获取确认和消息的等待时间，在生产者的配置文件内可配置。
从消费者角度看，副本具有相同的日志（带有相同的offset），消费者在日志中控制它的位置。
>- 对于消费者来说，kafka通过读取消息，保证消息至少可发送一次，处理消息后，保存他们的位置。
如果在处理消息后，消费者进程崩溃，但在保存他们位置前，另外一个消费者进程需要消费topic主题，可能会接收到前面的几条信息（已被处理）。

## 2. Log compaction
>日志压缩是比粗粒度的基于时间保存机制的更细粒度的消息保存机制。它确保最后一个已知值若要更新删除的主键，必须删除记录保存日志中topic分区的消息主键。
日志压缩也用于处理系统故障或重启等案例中。在kafka集群中，保存策略可根据每个主题设置(eg.基于时间、基于大小、基于日志压缩)。  
>>日志压缩确保以下内容：
>>- ①消息始终有序；  
>>- ②消息将具有顺序偏移量，且不会发生改变；  
>>- ③从偏移量0开始读取，或从日志的上一次消费记录的开始处，至少可以看到所有记录的最终状态。  

