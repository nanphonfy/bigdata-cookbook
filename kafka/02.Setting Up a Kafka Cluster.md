使用Kafka（发布订阅者消息系统），可创建多类型的集群，eg:
**单节点-单broker集群、
单节点-多broker集群、
多节点-多broker集群**。

**Kafka集群五个主要组件:**
>- **Topic:** 是生产者进行消息发布的类别或摘要名称
。在Kafka中，topic是分区的，每个分区含有序、不可变序列的消息。集群维护着
每个topic的分区日志。
分区中的每个消息都分配一个惟一的
序列ID称为offset；
>- **Broker:** Kafka集群由一个或多个服务器组成，每个服务器都可能有
一个或多个进程运行，称为broker。创建的topics在broker进程的上下文内；
>- **Zookeeper:** 作为Kafka
和消费者之间的协调接口。“ZooKeeper
通过一个共享的分层数据寄存器的命名空间(这些寄存器称作znodes)
来允许分布式进程相互协调，就像一个文件系统。
>>- 和标准文件系统的区别：每个
znode可有与之关联的数据（只局限他们持有的数据）。它的设计是为了存储、协调数据:状态信息、配置、位置信息等。
>- **生产者:** 选择适当的分区将数据发布到topic上。对于负载均衡，将消息分配到topic分区可用循环，也可用自定义函数；
>- **消费者:** 订阅topics的应用或进程，处理已发布的消息概要。

## 1. A single node–a single broker cluster
架构：  
>- producers、producers、producers...->kafka broker(单节点，单broker集群)->zookeeper    
>- kafka broker->consumers、consumers...->zookeeper

>kafka提供了默认、简单的配置文件，用来启动单机zookeeper实例。（单台zookeeper也可以设置kafka集群）  

`[root@localhost kafka_2.9.2-0.8.1.1]# bin/zookeeper-server-start.sh config/zookeeper.properties`

zookeeper.properties
```
# Data directory where the zookeeper snapshot is stored.
dataDir=/tmp/zookeeper
# The port listening for client request
clientPort=2181
# disable the per-ip limit on the number of connections since this is a
non-production config
maxClientCnxns=0
```
By default, the ZooKeeper server will listen on  *:2181/tcp .

### Starting the Kafka broker
启动kafka
` bin/kafka-server-start.sh
config/server.properties`

server.properties
```
# The id of the broker. This must be set to a unique integer for each
broker.
Broker.id=0
# The port the socket server listens on
port=9092
# The directory under which to store log files
log.dir=/tmp/kafka8-logs
# The default number of log partitions per topic.
num.partitions=2
# Zookeeper connection string
zookeeper.connect=localhost:2181
```
### Creating a Kafka topic
`bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafkatopic`

### Starting a consumer to consume messages
`bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafkatopic --from-beginning`

## 2. A single node – multiple broker clusters
架构：
>- producers、producers、producers...->kafka broker1、2、3...(单节点，多broker集群)->zookeeper  
>- kafka broker1、2、3...->consumers、consumers...->zookeeper


在单节点设置多个brokers，需为每个broker定义不同的server.properties。
```
broker1->server-1.properties
broker.id=1
port=9093
log.dir=/tmp/kafka-logs-1

broker2->server-2.properties
broker.id=2
port=9094
log.dir=/tmp/kafka-logs-2
...

bin/kafka-server-start.sh config/server-1.properties
bin/kafka-server-start.sh config/server-2.properties
...
```
### Starting a producer to send messages
>若要使单个生产者连接所有brokers，需要得到初始化的brokers列表。
eg.--broker-list localhost:9092, localhost:9093

启动生产者：

`bin/kafka-console-producer.sh --broker-list localhost:9092, localhost:9093 --topic replicated-kafkatopic`
>多个生产者连接所有brokers，给每个生产者输入如上命令。

### Starting a consumer to consume messages
`bin/kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic replicated-kafkatopic`

### Multiple nodes-multiple broker clusters
需在每个节点安装kafka并设置多个brokers，且所有来自不同节点的brokers需连接同一个zookeeper。

架构：
>- producers1、producers2、producers3...->kafka broker1、2、3...(node1，多broker集群)->zookeeper   
>- producers2、producers3...->kafka broker1、2、3...(node2，多broker集群)->zookeeper   
>- consumers1->zookeeper，consumers1->node1->zookeeper   
consumers2、3->node2->zookeeper

### The Kafka broker property list

```
#每个broker都用唯一的、非负数ID（做为broke的名称，让消费者可清晰的找到对应的host/port）
broker.id=0

#log日志存储目录，每个分区都会创建日志
log.dirs=/tmp/kafka-logs

#hostname:port/chroot格式，其中/chroot是基础目录（有效的命名空间，使所有kafka的znodes在应用中共享相同的zookeeper集群）
zookeeper.connect=localhost:2181

#broker的主机名，没有设置将绑定所有接口，并发布到zookeeper
host.name=Null

#每个topic的分区数
num.partitions=1

#若尝试生产、消费或抓取元数据到一个不存在的topic，将使用默认配置创建它
auto.create.topics.enable=True

#默认回复因子
default.replication.factor=1
This is the default replication factor for automatically created topics. 
```

