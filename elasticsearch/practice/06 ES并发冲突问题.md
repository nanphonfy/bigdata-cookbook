### 一、深度图解剖析Elasticsearch并发冲突问题
>电商场景：  
`程序工作流程：①读取商品信息(包括商品库存)；②用户下单；③更新商品信息(将库存减一)。`


>假设程序为多线程，可并发执行上述3步骤。
>- 有一款牙膏，库存100件，同时有两位用户读取牙膏数据分别购买，此时两个线程并发服务于两个人，同时在进行商品库存数据修改。  
这两个线程总有一个线程是先到的，假设为A，此时线程A会将牙膏库存设置为99件，然后线程B再次将牙膏库存设置为99件，此时结果就错了。  
正确情况，期望线程A将库存-1，设置为99件；然后线程B接着将库存-1，设置为98件，最后设置到ES中。  
>>上面说的流程和过程，就是ES中的并发冲突问题，会导致数据不准确。  
>>- ①有些场景下，不关心数据准确性。eg.若只是简单将数据写入ES，无论数据如何，都可以；甚至有些情况，算错了也可以。
>>- ②当并发操作ES的线程越多，或并发请求越多，或读取一份数据供用户查询、操作时间越长，可能这段时间内数据在ES中已被修改，那我们拿到的就是旧数据，基于旧数据去操作，结果肯定错了。

![image](https://raw.githubusercontent.com/nanphonfy/note-images/master/bigdata-cookbook/elasticsearch/practice/06/concurrency_conflict.png)

- 普通ES操作流程：  
>①先get document，商品信息，显示到网页，同时在内存中缓存该document数据；  
②当网页发起购买，直接基于内存的数据，进行计算和操作；  
③将计算后的结果写回ES中。

### 二、深度图解剖析悲观锁与乐观锁两种并发控制方案
#### 1.悲观锁并发控制方案
>各种情况都上锁，上锁后只有一个线程可操作这一条数据。不同场景，上的锁不同：行级锁、表级锁、读锁、写锁。

#### 2.悲观锁与乐观锁
>- ①悲观锁优点：方便，直接加锁对应用程序透明、不需额外操作。  
>- 缺点：并发能力很低，同一时间只能有一条线程操作数据。  

>- ②乐观锁优点：并发能力很高，不给数据加锁，大量线程并发操作。
>- 缺点：麻烦，每次更新时都先比对版本号，再重新加载数据，再修改、写。整个过程可能重复好几次。

>线程B去判断当前数据的版本号：version=1，与es数据的版本号：version=2，是否相同。  
版本号不同，说明数据已经被其他人修改过，此时用户B不会去更新，而是重新从es中读取最新的数据版本——99件，再次减1，变为98件，再执行上述流程，就可写入。

![image](https://raw.githubusercontent.com/nanphonfy/note-images/master/bigdata-cookbook/elasticsearch/practice/06/pressimistic_lock.png)

![image](https://raw.githubusercontent.com/nanphonfy/note-images/master/bigdata-cookbook/elasticsearch/practice/06/optimistic_lock.png)

### 三、上机演练：基于_version进行乐观锁并发控制

#### 1.kibana
- 构造一条数据
```
http://localhost:5601/app/kibana

PUT /test_index/test_type/1
{
  "test_field": "test value"
}

{
  "_index": "test_index",
  "_type": "test_type",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "created": true
}
```
- 模拟两个客户端，都获取到同一条数据

```
GET /test_index/test_type/1

{
  "_index": "test_index",
  "_type": "test_type",
  "_id": "1",
  "_version": 1,
  "found": true,
  "_source": {
    "test_field": "test value"
  }
}
```
- 其中一个客户端，先更新数据
>同时带上数据版本号，确保es中的数据版本号，跟客户端中的数据版本号是相同的，才能修改。
```
PUT /test_index/test_type/1?version=1 
{
  "test_field": "test client 1"
}

{
  "_index": "test_index",
  "_type": "test_type",
  "_id": "1",
  "_version": 2,
  "result": "updated",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "created": false
}
```
- 另外一个客户端，尝试基于version=1的数据去修改，同样带上version版本号，进行乐观锁的并发控制
```
PUT /test_index/test_type/1?version=1 
{
  "test_field": "test client 2"
}

{
  "error": {
    "root_cause": [
      {
        "type": "version_conflict_engine_exception",
        "reason": "[test_type][1]: version conflict, current version [2] is different than the one provided [1]",
        "index_uuid": "y2nEh3rlTJu0N_zLKxsKxQ",
        "shard": "3",
        "index": "test_index"
      }
    ],
    "type": "version_conflict_engine_exception",
    "reason": "[test_type][1]: version conflict, current version [2] is different than the one provided [1]",
    "index_uuid": "y2nEh3rlTJu0N_zLKxsKxQ",
    "shard": "3",
    "index": "test_index"
  },
  "status": 409
}
```
- 在乐观锁成功阻止并发问题后，尝试正确的更新
>基于最新的数据和版本号进行修改，修改后，带上最新的版本号，可能这个步骤需要反复执行好几次才能成功，特别在多线程并发更新同一条数据很频繁的情况下。

PUT /test_index/test_type/7?version=2 
```
PUT /test_index/test_type/1?version=2
{
  "test_field": "test client 2"
}

{
  "_index": "test_index",
  "_type": "test_type",
  "_id": "1",
  "_version": 3,
  "result": "updated",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "created": false
}
```

### 四、上机演练：基于external version进行乐观锁并发控制
#### 1.external version
>es提供了一个feature：可不用内部提供的_version版本号来进行并发控制，可以基于自己维护的版本号进行并发控制。eg.加入es的数据在mysql里也有一份，我们的应用系统本身也维护了一个版本号（无论是自己生成|程序控制）。
进行乐观锁并发控制时，可能并不想用es内部的_version来进行控制，而是用自己维护的version来进行控制。

`?version=1`  
`?version=1&version_type=external`

- version_type=external与前者区别
>唯一区别:  
_version——只有当提供的version与es中的_version一模一样时，才可进行修改，只要不一样，就报错；当version_type=external时，只有当提供的version比es中的_version大时，才能完成修改。  
>>es，_version=1，?version=1，才能更新成功;  
es，_version=1，?version>1&version_type=external，才能成功。

### 五、partial update实现原理、演练
#### 1.什么是partial update？
>语法类似于`PUT /index/type/id`——创建文档&替换文档  
- 一般对应到应用程序中，执行流程如下：   
>（1）应用程序先发起一个get请求，获取document，展示到前台界面，供用户查看、修改;  
（2）用户在前台界面修改数据，发送到后台;  
（3）后台会将用户修改的数据在内存中执行，然后封装好修改后的全量数据;  
（4）发送PUT请求到es中，进行全量替换;  
（5）es将老的document标记为deleted，然后重新创建一个新的document.

- partial update  
```
post /index/type/id/_update 
{
   "doc": {
      "要修改的少数几个field即可，不需要全量的数据"
   }
}
```
>看起来比较方便，每次传递少数几个发生修改的field即可，不需将全量的document数据发送过去。

#### 2、图解partial update实现原理以及其优点
>partial update看起来很方便，实际内部的原理优点是什么？

![image](https://raw.githubusercontent.com/nanphonfy/note-images/master/bigdata-cookbook/elasticsearch/practice/06/partial_update.png)

- ①查询，在界面上用户光修改可能10分钟，甚至半小时，修改后再回写，可能es的数据早就被人改了，所以并发冲突的情况就发生较多。  

- ②查询、修改和写回都发生在shard内部，一瞬间就完成（毫秒级别），可大大较少并发冲突。  

- ③partial update相较于全量替换的优点：  
1.所有查询、修改和写回都发生在es中的一个shard内部，避免了所有的网络数据传输的开销（减少2次网络请求），大大提升性能；  
2.减少了查询和修改中的时间间隔，可有效减少并发冲突的情况。

>其实es内部对partial update的实际执行，跟传统的全量替换方式是几乎一样的。
>>1.内部先获取document；  
2.将传过来的field更新到document的json中；  
3.将旧document标记为deleted；
4.将修改后的新document创建出来。
#### 3、上机演练partial update
```
PUT /test_index/test_type/10
{
  "test_field1": "test1",
  "test_field2": "test2"
}

POST /test_index/test_type/10/_update
{
  "doc": {
    "test_field2": "updated test2"
  }
}
```
### 六、图解partial update乐观锁并发控原理
partial update内部会自动执行我们之前所说的乐观锁并发控制策略。

![image](https://raw.githubusercontent.com/nanphonfy/note-images/master/bigdata-cookbook/elasticsearch/practice/06/partial_update_principle)

>- retry策略：  
>>1.再次获取document数据和最新版本号；  
2.基于最新版本号再去更新；  
3.若失败，重复1和2两个步骤。可以通过retry参数值指定最多重复次数。

### 七、mget批量查询
#### 1、批量查询优点
>一条条查询，若查100条数据，就要发100次网络请求，开销很大；  
若批量查询，查100条数据只要发送1次网络请求，性能开销缩减100倍。

#### 2、mget的语法
- （1）一条一条的查询
```
GET /test_index/test_type/1
GET /test_index/test_type/2
```
- （2）mget批量查询
```
GET /_mget
{
   "docs" : [
      {
         "_index" : "test_index",
         "_type" :  "test_type",
         "_id" :    1
      },
      {
         "_index" : "test_index",
         "_type" :  "test_type",
         "_id" :    2
      }
   ]
}

{
  "docs": [
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "1",
      "_version": 2,
      "found": true,
      "_source": {
        "test_field1": "test field1",
        "test_field2": "test field2"
      }
    },
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": "2",
      "_version": 1,
      "found": true,
      "_source": {
        "test_content": "my test"
      }
    }
  ]
}
```
- （3）若查询的document是index下的不同type
```
GET /test_index/_mget
{
   "docs" : [
      {
         "_type" :  "test_type",
         "_id" :    1
      },
      {
         "_type" :  "test_type",
         "_id" :    2
      }
   ]
}
```
- （4）若查询都在同一个index下的同一个type下，最简单了
```
GET /test_index/test_type/_mget
{
   "ids": [1, 2]
}
```
#### 3、mget的重要性
>一般在进行查询时，若一次性要查询多条数据，那一定要用batch批量操作的api，尽可能减少网络开销次数，将性能提升数倍，甚至数十倍，非常重要。  

### 八、演练bulk批量增删改
#### 1、bulk语法
- POST /_bulk
```
{ "delete": { "_index": "test_index", "_type": "test_type", "_id": "3" }} 
{ "create": { "_index": "test_index", "_type": "test_type", "_id": "12" }}
{ "test_field": "test12" }
{ "index":  { "_index": "test_index", "_type": "test_type", "_id": "2" }}
{ "test_field":    "replaced test2" }
{ "update": { "_index": "test_index", "_type": "test_type", "_id": "1", "_retry_on_conflict" : 3} }
{ "doc" : {"test_field2" : "bulk test1"} }
```
- 每一个操作要两个json串，语法如下：
>>{"action": {"metadata"}}  
{"data"}

>eg.要创建一个文档，放bulk里面，看起来会是这样子的：  
>>{"index": {"_index": "test_index", "_type", "test_type", "_id": "1"}}  
{"test_field1": "test1", "test_field2": "test2"}

- 有哪些类型的操作可以执行呢？  
>（1）delete：删除一个文档，只要1个json串就可以;  
（2）create：PUT /index/type/id/_create，强制创建;  
（3）index：普通的put操作，可以创建文档，也可全量替换文档;  
（4）update：执行的partial update操作。

>- bulk api对json语法，有严格的要求，每个json串不能换行，只能放一行，同时一个json串和一个json串之间，必须有一个换行；
>- bulk操作中，任意一个操作失败，是不会影响其他操作的，但在返回结果里，会有异常日志。

```
POST /test_index/_bulk
{ "delete": { "_type": "test_type", "_id": "3" }} 
{ "create": { "_type": "test_type", "_id": "12" }}
{ "test_field":    "test12" }
{ "index":  { "_type": "test_type" }}
{ "test_field":    "auto-generate id test" }
{ "index":  { "_type": "test_type", "_id": "2" }}
{ "test_field":    "replaced test2" }
{ "update": { "_type": "test_type", "_id": "1", "_retry_on_conflict" : 3} }
{ "doc" : {"test_field2" : "bulk test1"} }


POST /test_index/test_type/_bulk
{ "delete": { "_id": "3" }} 
{ "create": { "_id": "12" }}
{ "test_field":    "test12" }
{ "index":  { }}
{ "test_field":    "auto-generate id test" }
{ "index":  { "_id": "2" }}
{ "test_field":    "replaced test2" }
{ "update": { "_id": "1", "_retry_on_conflict" : 3} }
{ "doc" : {"test_field2" : "bulk test1"} }
```
#### 2、bulk size最佳大小
>bulk request会加载到内存里，若太大性能反而会下降，因此需要反复尝试一个最佳的bulk size。一般从1000~5000条数据开始，尝试逐渐增加。另外，若看大小的话，最好是在5~15MB之间。

### 九、总结
>01、02：快速入门最基本的原理、操作;  
03、04：深入剖析ES分布式基本原理;  
05、06：围绕document进行操作、讲解和分析.

#### 1、什么是distributed document store
>目前已经知道es是分布式的，包括一些基本原理、学习document相关的操作——增删改查。es的最核心功能，已经相对完整地写完了。

>Elasticsearch启动后，第一个最核心的功能：一个分布式的文档数据存储系统。——文档数据、存储系统。
>>- 文档数据：es可以存储和操作json文档类型的数据(es的核心数据结构)。  
>>- 存储系统：es可以对json文档类型的数据进行存储、查询、创建、更新、删除等操作。ES满足了这些功能，可以说已经是一个NoSQL的存储系统了。

>围绕着document的操作，其实就是把es当成了一个NoSQL存储引擎，一个可以存储文档类型数据的存储系统，在操作里面的document。  
es可以作为一个分布式的文档存储系统，所以我们的应用系统就可以基于这个概念去进行相关的应用程序开发了。

- 什么类型的应用程序呢？
>（1）数据量较大，es的分布式本质，可以快速扩容，承载大量数据;  
（2）数据结构灵活多变，随时可能会变化，且数据结构间的关系，非常复杂，如果用传统数据库，要面临大量的表;  
（3）对数据的相关操作较为简单，eg.简单的CRUD，用之前讲解的document操作就可搞定;  
（4）NoSQL数据库，适用的也是类似于上面的这种场景.
>>eg.一些网站系统或普通电商系统、博客系统，面向对象概念较复杂，但作为终端网站来说，没什么太复杂的功能，就是一些简单的CRUD操作，而且数据量可能较大。这时选用ES这种NoSQL型的数据存储，比传统的复杂功能支持SQL的关系型数据库，更加合适一些。无论是性能，还是吞吐量，可能都会更好。
