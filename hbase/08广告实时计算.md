互联网的"实时"含义是"感觉不到延迟"。数据采集->数据存储->对外服务。
## 1. 广告数据和流处理框架
- 网络广告特性
>eg.网页广告、电子邮件广告、搜索引擎关键词广告、搜索固定排名等，本质：向互联网用户传递营销信息的一种手段，是对用户注意力资源的合理利用。
>>特点：①传播范围广；②非强迫性传送资讯；③受众数量可准确统计；④灵活的时效性；⑤强烈的交互性和感官性。
- 数据类型
>最核心、最关键的四类：
>>1. 展现：广告位获得展现的数据，一般需发到服务端(统计分析广告展现量，adpv)，用JSON便于扩展；
>>2. 点击：广告位获得点击的数据(adclick)，同上；
>>3. 行为：广告位获得用户下载、安装或交易的数据(adaction)，同上；
>>4. 第三方数据监控：第三方广告监控公司参与广告投放监控产生的数据。
- 流处理框架
>数据流特点：①在线到达，实时处理；②数据流顺序无法控制；③数据流的某元素经处理，被丢弃或被归档存储。

框架：
1. Twitter storm：
>clojure和Java开发，借鉴了hadoop的计算模型。  
**应用场景：** ①信息流处理（实时处理数据和更新数据库）；②持续计算；③分布式远程程序调用（并行处理密集查询）。  
**特点：** ①编程模型简单；②支持各种编程语言；③容错（storm会管理工作进程和节点的故障）和水平扩展（计算是在多线程、进程、服务器间并行进行）；④可靠的消息处理（巧妙判断tuple是否丢失——acker为0即正确处理，否则通知spout重试）；⑤高效消息处理。   
>>storm集群由一个主节点和多个工作节点组成。主节点nimbus守护进程(分配代码、布置任务和故障检测)，工作节点supervisor守护进程(监听，开始并终止工作进程)。nimbus和supervisor都能快速失败，无状态，由zookeeper协调。spout是数据源，bolt处理数据，task是运行于spout或bolt的线程，woker是运行这些线程的进程、stream grouping规定了bolt接收何种数据作为输入，topology是由stream grouping连接起来的spout和bolt节点网络。
2. Alibaba jstorm：
>storm的Java版，一旦某个worker发生故障，调度器立即分配一个新woker替换。基于消息流水线处理，特别适合无状态计算。  
场景：①日志分析；②管道系统(eg.将数据库同步到hadoop)；③消息转化器（存到另外的消息中间件）；④统计分析器。  

………………

- 背景与需求
1. 背景
>需处理类似实时库存查询、实时竞价、实时业务规则更改部署等需求。
2. 需求
>1. 广告展示：①按地域(省+地级市)统计当天展现量；②按用户统计当天展现量；③按地域(省+地级市)、用户周期性统计(eg.一个月)的展现量趋势。
>2. 广告点击：每个广告当天点击量。

## 2. 概要设计
- 设计目标
>具备4方面能力：①可用性（能够保证高并发瞬间突发性情况，存在的数据丢失或连接持续等待，超时异常等问题）；②实时性;③平台通用性（封装通用接口，制定统一的数据接入格式，保证可扩展）；④扩展性(水平扩展，增加节点解决性能瓶颈)。
>>对系统性能要求延时30秒以内，峰值TPS=5000的访问请求。

- 系统架构  
日志接收层、生产者层、消息队列层（kafka框架）、消费者层、业务逻辑层（storm框架）、存储层（hbase）。

>1. 日志接收层：scribe、Nginx、syslog-ng、Apache http server等接收后存入本地磁盘。
>2. 生产者层：将日志文件从本地发送到kafka集群，实时监控某文件或目录。
>3. 消息队列层：kafka集群，负责输入数据的负载均衡、消息缓冲。(因其侧重吞吐量并具备缓冲功能，故折之)。
>4. 消费者层：需连通kafka和storm两集群。
>5. 业务逻辑层：storm框架，方便处理业务需求，实现快速计算。
>6. 存储层：hbase，可满足实时查询，水平扩展需求。

## 3. 详细设计
- 表结构设计
1. realtime_adpv_stat(广告实时展现统计表)  

表结构 | 值  
---|---
行键|ADID_省名称或市名称或UID_20170924
列族|pv
列名|cnt

2. realtime_adclick_stat  

表结构 | 值  
---|---
行键|ADID_20170924
列族|clk
列名|cnt

- 功能模块设计
1. kafka生产者
>1. 监控：日志采集节点的本地日志文件或目录，若发生变化，则读取否则延长检测时间，重复步骤；  
>2. 连接kafka：通过zookeeper连接，调用kafka的api；  
>3. 发送数据：调用kafka的生产者API的发送方法，写入过程即为推送过程，写入负载由kafka集群自行维护。  

2.消费者与业务逻辑模块
>storm-kafka中间件已实现连通（kafkaSpout），直接编写业务逻辑即可（topology）：第一个bolt负责将原始记录转换为行键格式，提取组合；第二个bolt负责将数据写入hbase，将增量值更新到计数字段。最后，还需实现topology的主方法(入口类)。


## 4. 核心功能实现
- 测试集群

组件|host1 | host2 | host3
---|---|---|---
zookeeper|zk1|zk2|zk3
kafka|broker1|broker2|broker3
storm|nimbus|supervisor1|supervisor2
hbase|hmaster|RS1|RS2
hdfs|NN|DN1|DN2

>kafka、storm、hbase都需要zookeeper作为消息通信和协调的基础组件。kafka"无主"状态，storm、hbase、hdfs"有主"状态，主服务进程在host1，子服务进程都在host2、host3。

测试环境的配置很可能造成单个节点负载和IO非常高，而成为瓶颈。生成环境应该采用"低耦合"的方式：
>zookeeper独立为共享物理集群，hbase和hdfs一起独立为一个物理集群，kafka和storm独立为两个物理集群，共需4个分布式独立的物理集群。
>>考虑到系统维护成本，生成环境一定要配置监控和报警系统。