## 1. 核心结构
RDBMS底层使用B树、B+树的存储结构，hbase使用LSM树(log-structured merge tree)。
- B+树
>树状数据结构，保持数据稳定有序，自底向上插入(与二叉树相反)，通过最大化每个内部节点的子节点数目来减少树的高度，不经常发生平衡操作，增加效率。  
>>在范围内可变子节点的数目，不像自平衡二叉树经常重新平衡，eg.2-3B树，可能有2或3个子节点/内部节点。节点通常表示为一组有序的元素和子指针。
- LSM树  
>算法对索引变更延迟+批量处理，使用基于内存和磁盘的组件（类似归并排序），对索引值查询可用其组件访问(除加锁期间)。减少磁盘磁臂开销(寻道+转动)，最适用索引插入比查询操作更常见的情况，eg.历史记录表+日志文件。

>**思想：划分不同等级的树。**  
>- eg.二级树，一份索引数据由2棵树（内存，可能是B树、AVL树等+磁盘，是B树）组成。数据先插入内存的树，超阈值，从左至右遍历，合并内存中叶子节点+磁盘中叶子节点，达到磁盘存储页大小，持久化到磁盘+更新父节点对叶子节点指针。
>- 磁盘的叶子节点（非叶子节点也被缓存到内存中）合并后，旧数据复制一份，与内存的数据一起顺序写到磁盘。
磁盘中树的非叶子节点也缓存到内存，先查内存的树，无，则查磁盘的树。磁盘树过大(数据量过大)，合并会变慢。  
>- 解决手段：建立层次。eg.内存的树为C0，磁盘的树为C1，C2，C3，...,Cn，合并顺序(C0，C1),(C1，C2)……。时间越长，flush越多，产生很多存储文件，而所有数据按key排序，不用重排。删除操作，存储删除标记，查找时跳过标记的，合并重写时被标记的才被丢弃。

>**区别：**
>>区别在于使用硬件的方式，特别是磁盘。  
**磁盘角度：** RDBMS通常都是寻道型（寻道速度每年大概提升5%），由B或B+树结构决定，log(N)。LSM-Tree是传输型（cpu、ram和磁盘空间每18~24个月翻番），在大规模下，传输比寻道高效。

>**优缺点：**
>>- 无太多更新，B+树工作得很好，以较繁重的优化保证较低的访问时间。越快越多地把数据放到随机位置，页面会越快变得碎片化。最终，数据传入速度可能超过优化进程重写现存文件的速度。改删以磁盘寻道速率级别进行，受限于最差的那个磁盘性能。  
>>- LSM-Tree以磁盘传输速率级别进行，使用日志文件和一个内存存储结构把随机写转换为顺序写，且读写操作独立，不产生竞争。可更好的扩展大规模数据，保证较一致的插入速率。

## 2.底层持久化
- 存储架构  
>- 两种基本文件类型：用于WAL（write-ahead log）和用于实际数据存储。  
>- **工作流程：** 客户端先连接zookeeper qurom(持有-ROOT-Region的服务器名，根据该信息访问拥有它的regionserver)，得到持有对应行键的.META.表region的服务器名。两个操作都会被缓存下来，最后查询.META.服务器，检索包含给定行键的region所在服务器。
>>启动hbase时，hmaster负责把region分配给每个hregionserver，包括-ROOT-和.META.表。
>- 结构类：hregionserver打开region，创建对应的hregion对象。当hregion被打开，就会为每个hcolumnfamily创建一个store实例(包含多个storefile实例(对hfile存储文件的简单封装)+一个memstore+一个由hregionserver共享的hlog实例(WAL相关类))。
- HDFS文件
>`hadoop fs -ls /habase/或hadoop fs -lsr /habase/`  
flush命令将内存数据写入存储文件，否则得等到超过配置的flush大小。  
>hbase文件：①hbase根目录下；②表目录下。
>- 根目录：由hlog实例处理的WAL文件(在/hbase/.logs/hregionserver子目录/几个hlog文件)，相同regionserver的region共享这些hlog。
日志文件(默认60分钟，hbase.regionserver.logroll.period)切换一次，当日志文件不再需要，会将变更持久化到存储文件，然后移动到/hbase/.oldlogs（默认10分钟后被master删除，hbase.master.logcleaner.ttl、hbase.master.logcleaner.interval隔几分钟检查）

```
/hbase/-ROOT-
/hbase/.META.
/hbase/.archive（存储表的归档和快照）
/hbase/.corrupt（损坏的日志文件）
/hbase/.logs
/hbase/.oldlogs
/hbase/.tmp
/hbase/hbase.id（集群唯一ID）
/hbase/hbase.version（集群文件格式版本号）
/hbase/splitlog（日志split进程用来存储中间split文件）
```

>- 表：每个表都有自己的目录：/hbase/表名/.tableinfo（保存HTableDescriptor序列化后的内容+元数据信息，eg.查表定义时读取）、/hbase/表名/.tmp(中间数据，eg.表被改动时)

>- region:  
查看HBase表在HDFS中的文件结构(http://blog.csdn.net/wuxiaoquan824212/article/details/52463664)  
HBase 在HDFS 上的目录树  
http://www.cnblogs.com/nexiyi/p/hbase_on_hdfs_directory.html  
eg.`USER_TEST_TABLE,AAA-AAA11110UC1,1364437081331.68b8ad74920040ba9f39141e908c67.`，eg.`USER_TEST_TABLE,AAA-AAA11110UC1,1364437081331`是region前部分，`.68b8ad74920040ba9f39141e908c67.`是哈希。  
.META.表的region命名规则和用户表不同，它使用Jenkins hash对region名称编码，可保证其名称总是合法。region因容量大小需split，会创建与之对应的splits目录(几秒)，创建成功后被移入表目录下形成两个新的region。
>>WAL的splitting和region的splitting有明显区别。

- region切分
>当一个region内的存储文件大于hbase.hregion.max.filesize时，该region会split成两个。regionserver通过在父region内创建切分目录，准备生成新的region(多线程)——包括**新的region目录+文件引用**，完成后把两新region目录移到表目录，然后更新.META.表，指明该region已被切分+子region名称、位置等。
启动合并，异步将存储文件从原始region写成两半，**原子性的取代引用文件**。原始region最终被清除(.META.表+磁盘)，master接到split通知，通过负载均衡将新region移动到其他服务器。
>>split的步骤都会通过zookeeper追踪，允许服务器出错，其他进程知晓region状态。
- 合并
>memstore的flush操作逐步增加磁盘上的文件数目，足够多时合并成规模更少但更大的文件。  
**两种类型：** 小合并(minor compaction)和大合并（major compaction）。  
>- 小合并负责将一些小文件合并成更大的文件，hbase.hstore.compaction.min.size(该region对应的memstore的flush容量大小)，所有小于最小合并阈值的都会被包含进合并列表(达到单次合并的文件数上限之前)。算法会保证老文件先被合并+确保总能够选出足够文件合并。
>- 大合并会将所有文件合并成一个。当memstore被flush到磁盘或执行compact 或 major_compact 或 API调用，会触发检查。前两者在服务端会先检查是否应该大合并，后两者会强制大合并。

- hfile格式
>一种文件存储格式的抽象，基于hadoop的TFile类实现，模仿BigTable架构的SSTable格式。有v1和v2版，以下围绕v1讲解。

data|data|...|meta|meta|...|file info|data index meta index|trailer
---|---|---|---|---|---|---|---|--- 

一个data包含：`magic keyvalue keyvalue ....`
每个block包含一个magic头和一系列序列化的keyvalue对象。
>文件是变长的，file info和trailer是定长的块。trailer会被写入文件末尾，包含指向其他block的指针，index block记录了data和meta block的偏移。block大小通过HColumnDescriptor配置，默认64KB（官方推荐8KB-1MB）。
>>若主要顺序访问，应设大一点的block（会降低随机访问性能，有大量数据需解压）。
若主要随机访问，应设小一点的block（需更多内存保存block index，创建文件变慢，因写入block后需对压缩编码器flush）。

>使用压缩算法，block大小不可控。默认，HDFS的block有64MB，是hfile的1000倍。他们二者没有关系，HDFS只看到hbase的二进制文件，不知道存储了什么。
- keyvalue格式
>一个简单的允许对内部数据进行zero-copy访问的底层字节数组。

key length|value length **|row length|row|column family length|column family|column qualifier|time stamp|key type|** value  
keyvalue结构-**加粗为key部分**

>标识key和value的长度，来保证数组可忽略key直接访问value。key包含了很多维度信息，处理小value值时，要尽量让key很小。选择一个短的rowkey和column family(1字节的列族名称，qualifier也要短)来控制二者大小比例。  
压缩有助于缓解该问题，包含重复数据压缩率会比较高，且存储文件的keyvalue排好序，可让类似的key靠在一起。
## 3. 预写日志
>为避免产生过多小文件，regionserver在未收集到足够数据flush到磁盘前，会一直把它保存在内存中(宕机丢失数据)。**hbase采用WAL策略：** 每次更新前，先写到日志中。类似MySQL的bin-log，WAL会记录数据的所有变更，当内存产生问题，通过日志恢复到宕机前的状态。WAL失败，则认为整个操作失败。
- 流程
>1. 客户端发送更新操作(put、delete、increment等)，包装keyvalue对象，通过RPC发送，到达具有对应region的某个hregionserver；
>2. keyvalue对象到达后，根据行键到达对应的hregion，数据先写入WAL，再存入响应的memstore中；
>3. memstore达到一定大小或过了特定时段后，数据会异步持久化到文件系统。期间数据都存在内存，WAL可保证数据不丢失。
>>日志存在HDFS上，不需要失败的服务器参与，其他服务器都能打开回放。
- 相关Java类
>- hlog
>>WAL的核心实现类，在一个hregion实例化时，唯一的hlog实例会被传递做为构造函数参数。当一个region接收到更新操作时，可将数据直接交给共享的WAL实例。
>- hlogkey  
>>存储：表名称、region信息、hlog序列号、修改操作何时写入日志的时间戳、cluster id(多集群间的复制)
>- logsyncer
>>定期执行日志flush的线程类，每隔很短时间(默认1s)调用sync访问。可通过HTableDescriptor设置日志flush延迟flag(默认false)。
>- logroller
>>主要用于清理日志。hbase默认60分钟打开一个新日志文件，时间久了会有大量文件需维护。
- 日志回放  
WAL保存各种操作日志，当服务器出现错误进行恢复，其恢复过程称为日志回放。
>1. 公用日志文件  
每个regionserver的所有修改操作都写入同一个HLog的日志文件内。该设计源自底层文件系统，若每个region单独保存日志，同时并发写入太多文件+日志切换会降低可扩展性。master必须等待宕机的机器所有日志都分离完毕才可重新部署上面的region。
>2. 日志切分  
master检查.logs目录是否存在日志。日志回放更新操作(put、delete、increment，其他操作不关心)。
回放前需按region剥离出来。
>>**切分过程：** 读取日志，按记录所属region分组，将其(更新操作)保持在目标region附近的一个文件中，用于后续恢复。现有版本使用zookeeper，当master确认某日志就绪，regionserver会进行竞争性选举，选出一个读取切分该日志文件。切分成功后，对应的文件会被移入实际的region目录中。
>3. 回放流程    
①hregionserver启动，初始化regionserver相关属性；②打开所管理的region，检查是否有日志文件；③将日志条目加入memstore；④memstore将数据flush到硬盘。

- 日志一致性  
>日志保证数据安全，最好能长时间处于打开状态。为能读到服务器crash时最后写入的位置或尽可能接近该位置，需要feature:append支持。
>>hadoop通常打开一个文件，写入大量数据，立即关闭。

## 4. 写入流程
- 客户端
>写请求：htable的put方法，不直接提交数据到服务端。而是简单检验数据，先写到缓存区，若已满则提交，否则继续往缓存区添加。  
重构数据：①定位put属于哪个region；②判断region属于哪个regionserver；③构造put和regionserver的映射关系。  
查找region：把当前put的行键和每个region是start rowkey和stop rowkey进行比较。  
提交请求：向各个regionserver并发（多线程）提交写请求。  
等待结果：异常或成功或成功异常同时存在。  
识别错误并重试。  
- 服务端
>获取region：根据region名字获取region对象，将数据批量更新到region上。  
准备写入：region检测（region是否可读写、资源是否就绪）、上锁（hbase内置锁机制避免脏数据）、解锁（用完后）、是否flush（超阈值）等。  
请求锁：请求尽可能多的锁，最少一个。  
更新时间戳：默认当前时间，可手动指定。  
写入memstore：memstore的MVCC(多版本并发控制)不会向前滚动，更新MVCC前，scan看不到。  
更新WAL：添加数据到WALEdit，将其添加到HLog，不同步。解锁，同步HLog，最后更新MVCC，成功写入memstore，scan和get可见。
## 5. 查询流程
>Get本质就是Scan(从start row到start row+1)。由于hbase内部无特定行或列的索引文件，hfile的一个block就是最小访问单元，为找请求数据，regionserver和底层store实例必须加载可能包含该数据的block，然后扫描。
- 客户端
>get调用后，客户端进入睡眠状态，有结果则中断执行返回RPC结果，默认10次(withRetries配置)。
- 服务端
>1. 定位region：-ROOT-表（只有一个region，永不切分）用于保存.META.表（存放实际用户表region位置信息）所有region信息。客户端缓存访问过的region位置信息在zookeeper上，首次查询或region发生变化(切分、合并)需要发送请求。  
递归逐层向上，给定rowkey匹配的.META.表的region所属的regionserver地址，若无效，退回上层-ROOT-表对应的.META.表region位置。也失败，则读zookeeper找到-ROOT-表region的位置。最坏情况需6次才能找到region。
>>三层 类B+树查找模式：①zookeeper，保存-ROOT-表的region信息；②-ROOT-表查找匹配.META.表的region;③.META.表检索用户表region信息。
>2. 数据校验转换：①检测列族是否合法；②将get转化为scan。
>3. region内查询：RegionScanner（转换为scan）、StoreScanner(列族级别扫描器，列族可能多个故可能有多个，含成员变量Store(一个MemStoreScanner和多个StoreFileScanner))。  
查找数据，过程：①时间戳或列过滤肯定不包含的数据(storefile或memstore)，缩小范围；②查看每个storefile最小的rowkey(升序（按行键、列族、列和时间戳排），放到队列)。获取数据，没有，则返回空。
## 6. 数据备份(replication)
在不同hbase集群间复制的一种方式，灾难恢复。
- 备份机制架构
>master-push架构模式(类似MySQL主从复制)，一个master可向任意slave集群复制（每个regionserver都会参与复制对应的修改）
regionserver是hlog备份的基础，hlog日志需要保存到HDFS，来复制到其他slave集群。为简化故障恢复，会将regionserver当前读取的日志位置保存到zookeeper(复制从最老日志开始读取)，master通过随机化尽量平衡到slave。
- 故障恢复
>zookeeper的高可用性和语义管理队列的传输。master集群的regionserver间都有一个观察者，其中一个死掉，其他都能得到通知。在死掉的regionserver的znode（包含一个具有一个队列的peers znode）创建一个lock的znode来竞争性选举，选举后的regionserver会将所有队列传输到自己的znode下，并删掉旧znode。完成后，对每个复制出的队列创建一个新的source线程（遵守read/filter/ship模式）

## 7. 数据压缩
- 支持的压缩算法
>- LZO:速度快，无损算法，线程安全，基于GPL协议(hbase基于Apache协议)，故需自行安装。
>- GZIP（GUNzip），相比LZO压缩率更高但速度更慢。
>- SNAPPY，高速压缩速度和合理压缩率，比ZLIB快，不兼容其他压缩格式。
- 配置
>先确保已安装压缩算法库。建表默认不压缩，值为NONE。对已存在的表重设压缩，需先下线表，修改压缩算法，最后上线表。
```
describe 'test'
disable 'test'
alter 'test',{NAME=>'cf1',COMPRESSION=>'SNAPPY'}
describe 'test'
enable 'test'
```
“尽信书不如无书”，坚持了解每个开源项目代码逻辑实现才是王道。